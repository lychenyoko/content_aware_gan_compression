<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0045)https://gvv.mpi-inf.mpg.de/projects/StyleRig/ -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Content-Aware GAN Compression, CVPR 2021 </title>
	


	<!-- Meta tags for Zotero grab citation -->
	<meta name="citation_title" content="Content-Aware GAN Compression">
	<meta name="citation_author" content="Liu, Yuchen">
	<meta name="citation_author" content="Shu, Zhixin">
	<meta name="citation_author" content="Li, Yijun">
	<meta name="citation_author" content="Lin, Zhe">
	<meta name="citation_author" content="Federico, Perazzi">
	<meta name="citation_author" content="Kung, Sun-Yuan">
	<meta name="citation_publication_date" content="2021">
	<meta name="citation_conference_title" content="CVPR">
	<meta name="citation_pdf_url" content="https://http://gvv.mpi-inf.mpg.de/projects/StyleRig//data/paper.pdf">

	<meta name="robots" content="index,follow">
	<meta name="description" content="
		StyleGAN generates photorealistic portrait images of faces with eyes, teeth, hair and context (neck, shoulders, background), but lacks a rig-like control over semantic face parameters that are interpretable in 3D, such as face pose, expressions, and scene illumination. Three-dimensional morphable face models (3DMMs) on the other hand offer control over the semantic parameters, but lack photorealism when rendered and only model the face interior, not other parts of a portrait image (hair, mouth interior, background). We present the first method to provide a face rig-like control over a pretrained and fixed StyleGAN via a 3DMM. A new rigging network, RigNet is trained between the 3DMM&#39;s semantic parameters and StyleGAN&#39;s input. The network is trained in a self-supervised manner, without the need for manual annotations. At test time, our method generates portrait images with the photorealism of StyleGAN and provides explicit control over the 3D semantic parameters of the face.">
	<link rel="author" href="http://www.mpi-inf.mpg.de/~atewari/">


	<!-- Fonts and stuff -->
	<link href="./assets/css" rel="stylesheet" type="text/css">
	<link rel="stylesheet" type="text/css" href="./assets/project.css" media="screen">
	<link rel="stylesheet" type="text/css" media="screen" href="./assets/iconize.css">
	<script src="./assets/prettify.js"></script>
</head>

<body>
	<div id="content">
		<div id="content-inner">
			<div class="section logos" style="text-align:center">
			<a href="https://research.adobe.com/" target="_blank"><img src="./assets/Adobe_Logo.png" height="35" border="0"></a>
			<a href="https://www.princeton.edu/" target="_blank"><img src="./assets/Princeton_Logo.png" height="35" border="0"></a>
			</div>

			<div class="section head">
			
				<h1>Content-Aware GAN Compression</h1>

				<div class="authors">
					<a href="https://lychenyoko.github.io/" target="_blank">Yuchen Liu</a><sup> 1</sup>&nbsp;&nbsp;
					<a href="https://zhixinshu.github.io/" target="_blank">Zhixin Shu</a><sup> 2</sup>&nbsp;&nbsp;
					<a href="https://yijunmaverick.github.io/" target="_blank">Yijun Li</a><sup> 2</sup>&nbsp;&nbsp;
					<a href="https://sites.google.com/site/zhelin625/" target="_blank">Zhe Lin</a><sup> 2</sup>&nbsp;&nbsp;
					<a href="https://fperazzi.github.io/" target="_blank">Federico Perazzi</a><sup> 2</sup>&nbsp;&nbsp;
					<a href="https://ece.princeton.edu/people/sun-yuan-kung" target="_blank">S.Y. Kung</a><sup> 1</sup>&nbsp;&nbsp;
				</div>

				<div class="affiliations">
					<sup>1</sup><a href="https://www.princeton.edu/" target="_blank">Princeton University</a>&nbsp;&nbsp;
					<sup>2</sup><a href="https://research.adobe.com/" target="_blank">Adobe Research</a>&nbsp;&nbsp;
				</div>

				<div class="venue"><a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR 2021</a></div>
				
			</div>

			<div class="section abstract">
			</div>

			<div class="section teaser">
				<!-- <iframe width="640" height="360" src="data/video.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
				<iframe src="./assets/eaW_P85wQ9k.html" allow="autoplay; encrypted-media" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" width="560" height="315" frameborder="0"></iframe>
				<!--iframe src="./data/video.mp4" allow="autoplay; encrypted-media" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" width="560" height="315" frameborder="0"></iframe-->				
				<p style="font-size:11px; text-align:center">
					Download Video: <a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/video.mp4" target="_blank">HD</a> (MP4, 111 MB)
				</p>
			</div>

			<div class="section abstract">
				<h2>Abstract</h2>
				<p>
				StyleGAN generates photorealistic portrait images of faces with eyes, teeth, hair and context (neck, shoulders, background), but lacks a rig-like control over semantic face parameters that are interpretable in 3D, such as face pose, expressions, and scene illumination. Three-dimensional morphable face models (3DMMs) on the other hand offer control over the semantic parameters, but lack photorealism when rendered and only model the face interior, not other parts of a portrait image (hair, mouth interior, background). We present the first method to provide a face rig-like control over a pretrained and fixed StyleGAN via a 3DMM. A new rigging network, \textit{RigNet} is trained between the 3DMM's semantic parameters and StyleGAN's input. The network is trained in a self-supervised manner, without the need for manual annotations. At test time, our method generates portrait images with the photorealism of StyleGAN and provides explicit control over the 3D semantic parameters of the face.	  </p>
				<p></p>
			</div>

			<div class="section downloads">
				<h2>Downloads</h2>
				<center>
				<ul>
					<li class="grid">
						<div class="griditem">
							<a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/paper.pdf" target="_blank" class="imageLink"><img src="./assets/pdf.png"></a><br>
							Paper<br>
							<a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/paper.pdf" target="_blank">PDF, 4 MB</a>
						</div>
					</li>
					<li class="grid">
						<div class="griditem">
							<a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/supp.pdf" target="_blank" class="imageLink"><img src="./assets/pdf.png"></a><br>
							Supplemental document<br>
							<a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/supp.pdf" target="_blank">PDF, 3 MB</a>
						</div>
					</li>
					<li class="grid"> 
						<div class="griditem"> 
						<a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/video.mp4" target="_blank" class="imageLink"><img src="./assets/mp4.png"></a><br>
						Main video<br> 
						<a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/video.mp4" target="_blank">MP4, 111 MB</a>
						<br> 
						</div>
					</li>
					<!-- <li class="grid">  -->
						<!-- <div class = "griditem">  -->
						<!-- <a href="data/slides.pptx" target="_blank" class="imageLink"><img src = "images/ppt.png"></a><br /> -->
						<!-- Slides<br />  -->
						<!-- <a href="data/slides.pptx" target="_blank">pptx, 423 MB</a> -->
						<!-- <br />  -->
						<!-- </div> -->
					<!-- </li>	 -->
				</ul>
				</center>
			</div>
			<br>
			<div class="section list">
				<h2>Citation</h2>
				<p><a href="https://gvv.mpi-inf.mpg.de/projects/StyleRig/data/bibtex.bib" target="_blank">BibTeX, 1 KB</a></p>
				<div class="section bibtex">
					<pre>@inproceedings{liu2021content,
  title     = {Content-Aware GAN Compression},
  author    = {Liu, Yuchen and Shu, Zhixin and Li, Yijun and Lin, Zhe and Perazzi, Federico and Kung, S.Y.},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2021},
}					</pre>
				</div>
			</div>


			<!--div class="section acknowledgments">
				<h2>Acknowledgments</h2>
				<p>
					This work was funded by the ERC Consolidator Grant 4DRepLy (770784).
				</p>
			</div-->

			<div class="section contact">
				<h2>Contact</h2>
				For questions, clarifications, please get in touch with:<br>
				Ayush Tewari<br><a href="mailto:atewari@mpi-inf.%6D%70%67.de">atewari@mpi-inf.mpg.de</a>  
			</div>

			<div class="section">
				<hr class="smooth">
				This page is <a href="http://www.zotero.org/" target="_blank">Zotero</a> translator friendly. Page last updated 
				<script type="text/javascript">
					var m = "This page was last updated: " + document.lastModified;
					var p = m.length-9;
					document.writeln("<left>");
					document.write(m.substring(p, 0) + ".");
					document.writeln("</left>");
				</script><left>
This page was last updated: 09/22/2020.</left>

				<a href="https://www.mpi-inf.mpg.de/imprint/">Imprint</a>. <a href="https://data-protection.mpi-klsb.mpg.de/inf/gvv.mpi-inf.mpg.de/projects/">Data Protection</a>.
			</div>
		</div>
	</div>


</body></html>